# -*- coding: utf-8 -*-
"""model

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1XDOJ5qYSxpK8ZHfezC-_0XXGibYkzb-7
"""

# Commented out IPython magic to ensure Python compatibility.
from google.colab import drive
drive.mount('/content/drive')
# %cd /content/drive/MyDrive/UTKFace/

# modules for data manipulation and data preprocessing
import pandas as pd
import numpy as np
from numpy import asarray

# modules for iamge processing
import os
from tqdm.notebook import tqdm
from PIL import Image

# modules for data visualization
import matplotlib.pyplot as plt
import seaborn as sns

# modules to create, train and save the model
import tensorflow as tf
from keras.preprocessing.image import load_img
from keras.models import Sequential, Model
from keras.layers import Dense, Conv2D, Dropout, Flatten, MaxPooling2D, Input

# to ignore the warnings syntax generated
import warnings
warnings.filterwarnings('ignore')

# set the directory of the dataset (directory path may differ)
BASE_DIR = '../UTKFace/'

# create array to store the image filename with their corresponding age and gender
image_paths = []
age_labels = []
gender_labels = []

# for each image filename, we split them into their path, age and gender
for filename in tqdm(os.listdir(BASE_DIR)):
    image_path = os.path.join(BASE_DIR, filename) # assign filename to image path
    temp = filename.split('_')                    # split the filename with "_"
    age = int(temp[0])                            # get the age
    gender = int(temp[1])                         # get the gender
    image_paths.append(image_path)                # store image path into its array
    age_labels.append(age)                        # store age into its array
    gender_labels.append(gender)                  # store gender into its array

# convert those array into a dataframe
df = pd.DataFrame()
df['image'], df['age'], df['gender'] = image_paths, age_labels, gender_labels
df

# this is a function to preprocess the image 
def extract_features(images):
    features = []                                             # create a new array for the processed image
    for image in tqdm(images):
        img = load_img(image, grayscale=True)                 # load the image as grayscale
        img = img.resize((128, 128), Image.ANTIALIAS)         # resize the image and apply antialias
        img = np.array(img)                                   # get the pixels of image
        features.append(img)                                  # store the pixel
        
    features = np.array(features)                             # make the array a NumPy array
    features = features.reshape(len(features), 128, 128, 1)   # reshape the array for the model
    return features

X = extract_features(df['image'])

X = X/255.0                         # normalize the input
y_age = np.array(df['age'])         # prepare training output for age  
y_gender = np.array(df['gender'])   # prepare training output for gender

# creation of model begins here

inputs = Input((128, 128, 1)) # set the input size
# create 4 convolutional layers followed by maxpooling
conv_1 = Conv2D(32, kernel_size=(3, 3), activation='relu') (inputs)
maxp_1 = MaxPooling2D(pool_size=(2, 2)) (conv_1)
conv_2 = Conv2D(64, kernel_size=(3, 3), activation='relu') (maxp_1)
maxp_2 = MaxPooling2D(pool_size=(2, 2)) (conv_2)
conv_3 = Conv2D(128, kernel_size=(3, 3), activation='relu') (maxp_2)
maxp_3 = MaxPooling2D(pool_size=(2, 2)) (conv_3)
conv_4 = Conv2D(256, kernel_size=(3, 3), activation='relu') (maxp_3)
maxp_4 = MaxPooling2D(pool_size=(2, 2)) (conv_4)

# flattens the multi-dimensional input tensors into a single dimension
flatten = Flatten() (maxp_4)

# create 2 seperate fully connected layers
dense_1 = Dense(256, activation='relu') (flatten)
dense_2 = Dense(256, activation='relu') (flatten)

# set dropout rate for neuron in each layer to prevent overfitting
dropout_1 = Dropout(0.3) (dense_1)
dropout_2 = Dropout(0.3) (dense_2)

# set the output layer activation function as sigmoid for gender and ReLu for age
output_1 = Dense(1, activation='sigmoid', name='gender_out') (dropout_1)
output_2 = Dense(1, activation='relu', name='age_out') (dropout_2)

# create the model with input and outputs
model = Model(inputs=[inputs], outputs=[output_1, output_2])

# compile the result of loss function and the metrics of each training process
model.compile(loss=['binary_crossentropy', 'mae'], optimizer='adam', metrics=['acc'])

# Commented out IPython magic to ensure Python compatibility.
# plot the model
# %cd /content/drive/MyDrive/Soft Computing/
tf.keras.utils.plot_model(model)

# train model with your preferable batch size, epochs and validation set split ratio
history = model.fit(x=X, y=[y_gender, y_age], batch_size=32, epochs=15, validation_split=0.2)

# save model and the history of each epoch
tf.keras.models.save_model(model,'my_model.hdf5')
history = pd.DataFrame(history.history)
history.to_csv('history.csv')

# plot accuracy rate for gender model
acc = history.history['gender_out_acc']
val_acc = history.history['val_gender_out_acc']
epochs = range(len(acc))

plt.plot(epochs, acc, 'b', label='Training Accuracy')
plt.plot(epochs, val_acc, 'r', label='Validation Accuracy')
plt.title('Accuracy Graph')
plt.legend()
plt.figure()

# plot loss rate for gender model
loss = history.history['gender_out_loss']
val_loss = history.history['val_gender_out_loss']

plt.plot(epochs, loss, 'b', label='Training Loss')
plt.plot(epochs, val_loss, 'r', label='Validation Loss')
plt.title('Loss Graph')
plt.legend()
plt.show()

# plot loss rate OR mean absolute error (mae) for gender model
mae = history.history['age_out_loss']
val_mae = history.history['val_age_out_loss']
epochs = range(len(mae))

plt.plot(epochs, mae, 'b', label='Training MAE')
plt.plot(epochs, val_mae, 'r', label='Validation MAE')
plt.title('MAE Graph')
plt.legend()

# map labels for gender
gender_dict = {0:'Male', 1:'Female'}

image_index = 23
print("Original Gender:", gender_dict[y_gender[image_index]], "Original Age:", y_age[image_index])
# predict from model
pred = model.predict(X[image_index].reshape(1, 128, 128, 1))
pred_gender = gender_dict[round(pred[0][0][0])]
pred_age = round(pred[1][0][0])
print("Predicted Gender:", pred_gender, "Predicted Age:", pred_age)
plt.axis('off')
plt.imshow(X[image_index].reshape(128, 128), cmap='gray');

from google.colab import files
uploaded = files.upload()

photo = Image.open('Lim Jing Yao.jpg')
photo = photo.resize((128,128))
photo = photo.convert(mode='L')
photo = asarray(photo)
photo = photo.reshape(128,128,1)
photo = photo/255.0

pred = model.predict(photo.reshape(1, 128, 128, 1))
pred_gender = gender_dict[round(pred[0][0][0])]
pred_age = round(pred[1][0][0])
print("Predicted Gender:", pred_gender, "Predicted Age:", pred_age)
plt.axis('off')
plt.imshow(photo.reshape(128, 128), cmap='gray');